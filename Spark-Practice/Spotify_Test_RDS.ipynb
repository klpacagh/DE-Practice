{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "import pymysql\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to RDS\n",
    "endpoint = 'my-db.co9whbkecuet.us-east-1.rds.amazonaws.com'\n",
    "username = 'admin'\n",
    "password = 'Password1!'\n",
    "database = 'SALES_DB'\n",
    "connection = pymysql.connect(host=endpoint, user=username, passwd=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SALES_DB',)\n",
      "('airflow_db',)\n",
      "('information_schema',)\n",
      "('mysql',)\n",
      "('performance_schema',)\n"
     ]
    }
   ],
   "source": [
    "# setup env - create tables\n",
    "cur = connection.cursor()\n",
    "\n",
    "# Use all the SQL you like\n",
    "# cur.execute(\"CREATE DATABASE airflow_db CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;\")\n",
    "# cur.execute(\"USE airflow_db\")\n",
    "# cur.execute(\"CREATE USER 'airflow_user' IDENTIFIED BY 'airflow_pass';\")\n",
    "# cur.execute(\"GRANT ALL PRIVILEGES ON airflow_db.* TO 'airflow_user';\")\n",
    "cur.execute(\"SHOW DATABASES\")\n",
    "\n",
    "# cur.execute(\"SHOW TABLES\")\n",
    "# cur.execute(\" \\\n",
    "#                 CREATE TABLE IF NOT EXISTS SALES ( \\\n",
    "#                 ORDER_ID INT(12) NOT NULL, \\\n",
    "#                 QTY_ORDERED INT(100), \\\n",
    "#                 PRICE_PER DECIMAL(6,2), \\\n",
    "#                 SALES DECIMAL(12,2), \\\n",
    "#                 ORDER_DATE DATE \\\n",
    "#                 ); \\\n",
    "#             \")\n",
    "# cur.execute(\"DESCRIBE SALES\")    \n",
    "\n",
    "# cur.execute(\"CREATE TABLE IF NOT EXISTS SALES_SUM ( \\\n",
    "#     SALES_TOTAL_ID INT AUTO_INCREMENT, \\\n",
    "#     SALES_TOTAL DECIMAL(10,2), \\\n",
    "#     PRIMARY KEY (SALES_TOTAL_ID) \\\n",
    "#     );\")\n",
    "\n",
    "#cur.execute(\"insert into SALES_SUM (SALES_TOTAL) values (4211.20);\")\n",
    "\n",
    "# cur.execute(\"select * from SALES_SUM;\")\n",
    "\n",
    "connection.commit()\n",
    "# cur.execute(\"DELETE FROM SALES_SUM\")\n",
    "# connection.commit()\n",
    "# print all the first cell of all the rows\n",
    "for row in cur.fetchall():\n",
    "    print(row)\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST\n",
    "import sqlalchemy\n",
    "import pandas as pd \n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import *\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import sqlite3\n",
    "import pymysql\n",
    "\n",
    "\n",
    "# Generate your token here:  https://developer.spotify.com/console/get-recently-played/\n",
    "# Note: You need a Spotify account (can be easily created for free)\n",
    "\n",
    "def check_if_valid_data(df: pd.DataFrame) -> bool:\n",
    "    # Check if dataframe is empty\n",
    "    if df.empty:\n",
    "        print(\"No songs downloaded. Finishing execution\")\n",
    "        return False \n",
    "\n",
    "    # Primary Key Check\n",
    "    if pd.Series(df['played_at']).is_unique:\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception(\"Primary Key check is violated\")\n",
    "\n",
    "    # Check for nulls\n",
    "    if df.isnull().values.any():\n",
    "        raise Exception(\"Null values found\")\n",
    "\n",
    "    # Check that all timestamps are of yesterday's date\n",
    "#     yesterday = datetime.datetime.now() - datetime.timedelta(days=1)\n",
    "#     yesterday = yesterday.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "#     timestamps = df[\"timestamp\"].tolist()\n",
    "#     for timestamp in timestamps:\n",
    "#         if datetime.datetime.strptime(timestamp, '%Y-%m-%d') != yesterday:\n",
    "#             raise Exception(\"At least one of the returned songs does not have a yesterday's timestamp\")\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_LOCATION = \"mysql+pymysql://airflow_user:airflow_pass@my-db.co9whbkecuet.us-east-1.rds.amazonaws.com:3306/airflow_db\"\n",
    "USER_ID = '22xzv4gulalicawnisxrbiyna'\n",
    "TOKEN = 'BQCkoBVw9C0oiyexpxdeSOhcUk83Vn3a0LhuVfNo8vBB-6I5dQsOxuTWGAD8DEQ8Z8lkpdC1CX9GKcGECCVAU_auIeztb2PbBa76HlNh91yL38uPsRzqt4-2cUpRb32OIOxK7lGpqpb8UVGEN59c3W4cc54bTxsbQWHI6LBZ'\n",
    "\n",
    "  # Extract part of the ETL process\n",
    "\n",
    "headers = {\n",
    "    \"Accept\" : \"application/json\",\n",
    "    \"Content-Type\" : \"application/json\",\n",
    "    \"Authorization\" : \"Bearer {token}\".format(token=TOKEN)\n",
    "}\n",
    "\n",
    "# Convert time to Unix timestamp in miliseconds      \n",
    "today = datetime.datetime.now()\n",
    "yesterday = today - datetime.timedelta(days=1)\n",
    "yesterday_unix_timestamp = int(yesterday.timestamp()) * 1000\n",
    "\n",
    "# Download all songs you've listened to \"after yesterday\", which means in the last 24 hours      \n",
    "r = requests.get(\"https://api.spotify.com/v1/me/player/recently-played?after={time}\".format(time=yesterday_unix_timestamp), headers = headers)\n",
    "\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data valid, proceed to Load stage\n",
      "Opened database successfully\n",
      "Close database successfully\n"
     ]
    }
   ],
   "source": [
    "song_names = []\n",
    "artist_names = []\n",
    "played_at_list = []\n",
    "timestamps = []\n",
    "\n",
    "# Extracting only the relevant bits of data from the json object      \n",
    "for song in data[\"items\"]:\n",
    "    song_names.append(song[\"track\"][\"name\"])\n",
    "    artist_names.append(song[\"track\"][\"album\"][\"artists\"][0][\"name\"])\n",
    "    played_at_list.append(song[\"played_at\"])\n",
    "    timestamps.append(song[\"played_at\"][0:10])\n",
    "\n",
    "# Prepare a dictionary in order to turn it into a pandas dataframe below       \n",
    "song_dict = {\n",
    "    \"song_name\" : song_names,\n",
    "    \"artist_name\": artist_names,\n",
    "    \"played_at\" : played_at_list,\n",
    "    \"timestamp\" : timestamps\n",
    "}\n",
    "\n",
    "song_df = pd.DataFrame(song_dict, columns = [\"song_name\", \"artist_name\", \"played_at\", \"timestamp\"])\n",
    "\n",
    "# Validate\n",
    "if check_if_valid_data(song_df):\n",
    "    print(\"Data valid, proceed to Load stage\")\n",
    "\n",
    "# Load\n",
    "\n",
    "\n",
    "engine = sqlalchemy.create_engine(DATABASE_LOCATION)\n",
    "#conn = sqlite3.connect('my_played_tracks.sqlite')\n",
    "\n",
    "endpoint = 'my-db.co9whbkecuet.us-east-1.rds.amazonaws.com'\n",
    "username = 'airflow_user'\n",
    "password = 'airflow_pass'\n",
    "database = 'airflow_db'\n",
    "conn = pymysql.connect(host=endpoint, user=username, passwd=password, db=database, port=3306)\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "sql_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS my_played_tracks(\n",
    "    song_name VARCHAR(200),\n",
    "    artist_name VARCHAR(200),\n",
    "    played_at VARCHAR(200),\n",
    "    timestamp VARCHAR(200),\n",
    "    CONSTRAINT primary_key_constraint PRIMARY KEY (played_at)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(sql_query)\n",
    "print(\"Opened database successfully\")\n",
    "\n",
    "try:\n",
    "    song_df.to_sql(\"my_played_tracks\", engine, index=False, if_exists='append')\n",
    "except:\n",
    "    print(\"Data already exists in the database\")\n",
    "\n",
    "conn.close()\n",
    "print(\"Close database successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
