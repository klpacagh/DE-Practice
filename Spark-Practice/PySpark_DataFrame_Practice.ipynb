{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder.appName(\"PySparkDFPractice\").getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StructType is a collection of StructFields that define the column name, column data type\n",
    "# and a boolean value to specify if the field can be nullable or not\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"firstName\", StringType(), True),\n",
    "    StructField(\"middleName\", StringType(), True),\n",
    "    StructField(\"lastName\", StringType(), True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- middleName: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstName|middleName|lastName|id   |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|James    |          |Smith   |36636|M     |3000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./test_data/fire-incidents.csv\"\n",
    "file_df = (spark.read.format(\"csv\")\n",
    "          .option(\"header\", True)\n",
    "          .option(\"inferSchema\", True)\n",
    "          .load(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+-------------+\n",
      "|IncidentNumber|       IncidentDate|         City|\n",
      "+--------------+-------------------+-------------+\n",
      "|      20104668|2020-09-11 00:00:00|San Francisco|\n",
      "|      20104708|2020-09-11 00:00:00|San Francisco|\n",
      "|      20104648|2020-09-10 00:00:00|San Francisco|\n",
      "|      20104598|2020-09-10 00:00:00|San Francisco|\n",
      "|      20104575|2020-09-10 00:00:00|San Francisco|\n",
      "|      20104477|2020-09-10 00:00:00|San Francisco|\n",
      "|      20104443|2020-09-10 00:00:00|San Francisco|\n",
      "|      20104605|2020-09-10 00:00:00|San Francisco|\n",
      "|      20104474|2020-09-10 00:00:00|San Francisco|\n",
      "|      20104652|2020-09-10 00:00:00|San Francisco|\n",
      "+--------------+-------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# referred to as a Projection after an action is used\n",
    "file_df.select(\"IncidentNumber\", \"IncidentDate\", \"City\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- ExposureNumber: integer (nullable = true)\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- IncidentDate: timestamp (nullable = true)\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- AlarmDtTm: timestamp (nullable = true)\n",
      " |-- ArrivalDtTm: timestamp (nullable = true)\n",
      " |-- CloseDtTm: timestamp (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- ZIPCode: string (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- SuppressionUnits: integer (nullable = true)\n",
      " |-- SuppressionPersonnel: integer (nullable = true)\n",
      " |-- EMSUnits: integer (nullable = true)\n",
      " |-- EMSPersonnel: integer (nullable = true)\n",
      " |-- OtherUnits: integer (nullable = true)\n",
      " |-- OtherPersonnel: integer (nullable = true)\n",
      " |-- FirstUnitOnScene: string (nullable = true)\n",
      " |-- EstimatedPropertyLoss: integer (nullable = true)\n",
      " |-- EstimatedContentsLoss: double (nullable = true)\n",
      " |-- FireFatalities: integer (nullable = true)\n",
      " |-- FireInjuries: integer (nullable = true)\n",
      " |-- CivilianFatalities: integer (nullable = true)\n",
      " |-- CivilianInjuries: integer (nullable = true)\n",
      " |-- NumberofAlarms: integer (nullable = true)\n",
      " |-- PrimarySituation: string (nullable = true)\n",
      " |-- MutualAid: string (nullable = true)\n",
      " |-- ActionTakenPrimary: string (nullable = true)\n",
      " |-- ActionTakenSecondary: string (nullable = true)\n",
      " |-- ActionTakenOther: string (nullable = true)\n",
      " |-- DetectorAlertedOccupants: string (nullable = true)\n",
      " |-- PropertyUse: string (nullable = true)\n",
      " |-- AreaofFireOrigin: string (nullable = true)\n",
      " |-- IgnitionCause: string (nullable = true)\n",
      " |-- IgnitionFactorPrimary: string (nullable = true)\n",
      " |-- IgnitionFactorSecondary: string (nullable = true)\n",
      " |-- HeatSource: string (nullable = true)\n",
      " |-- ItemFirstIgnited: string (nullable = true)\n",
      " |-- HumanFactorsAssociatedwithIgnition: string (nullable = true)\n",
      " |-- StructureType: string (nullable = true)\n",
      " |-- StructureStatus: string (nullable = true)\n",
      " |-- FloorofFireOrigin: integer (nullable = true)\n",
      " |-- FireSpread: string (nullable = true)\n",
      " |-- NoFlameSpead: string (nullable = true)\n",
      " |-- Numberoffloorswithminimumdamage: integer (nullable = true)\n",
      " |-- Numberoffloorswithsignificantdamage: integer (nullable = true)\n",
      " |-- Numberoffloorswithheavydamage: integer (nullable = true)\n",
      " |-- Numberoffloorswithextremedamage: integer (nullable = true)\n",
      " |-- DetectorsPresent: string (nullable = true)\n",
      " |-- DetectorType: string (nullable = true)\n",
      " |-- DetectorOperation: string (nullable = true)\n",
      " |-- DetectorEffectiveness: string (nullable = true)\n",
      " |-- DetectorFailureReason: string (nullable = true)\n",
      " |-- AutomaticExtinguishingSystemPresent: string (nullable = true)\n",
      " |-- AutomaticExtinguishingSytemType: string (nullable = true)\n",
      " |-- AutomaticExtinguishingSytemPerfomance: string (nullable = true)\n",
      " |-- AutomaticExtinguishingSytemFailureReason: string (nullable = true)\n",
      " |-- NumberofSprinklerHeadsOperating: integer (nullable = true)\n",
      " |-- SupervisorDistrict: integer (nullable = true)\n",
      " |-- AnalysisNeighborhood: string (nullable = true)\n",
      " |-- point: string (nullable = true)\n",
      " |-- NeighborhoodsOld: integer (nullable = true)\n",
      " |-- ZipCodes: integer (nullable = true)\n",
      " |-- FirePreventionDistricts: integer (nullable = true)\n",
      " |-- PoliceDistricts: integer (nullable = true)\n",
      " |-- SupervisorDistricts: integer (nullable = true)\n",
      " |-- CivicCenterHarmReductionProjectBoundary: integer (nullable = true)\n",
      " |-- 2017FixItZones: integer (nullable = true)\n",
      " |-- HSOCZones: integer (nullable = true)\n",
      " |-- CentralMarketTenderloinBoundary: integer (nullable = true)\n",
      " |-- CentralMarketTenderloinBoundaryPolygonUpdated: integer (nullable = true)\n",
      " |-- HSOCZonesasof20180605: integer (nullable = true)\n",
      " |-- Neighborhoods: integer (nullable = true)\n",
      " |-- SFFindNeighborhoods: integer (nullable = true)\n",
      " |-- CurrentPoliceDistricts: integer (nullable = true)\n",
      " |-- CurrentSupervisorDistricts: integer (nullable = true)\n",
      " |-- AnalysisNeighborhoods: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IncidentNumber',\n",
       " 'ExposureNumber',\n",
       " 'ID',\n",
       " 'Address',\n",
       " 'IncidentDate',\n",
       " 'CallNumber',\n",
       " 'AlarmDtTm',\n",
       " 'ArrivalDtTm',\n",
       " 'CloseDtTm',\n",
       " 'City',\n",
       " 'ZIPCode',\n",
       " 'Battalion',\n",
       " 'StationArea',\n",
       " 'Box',\n",
       " 'SuppressionUnits',\n",
       " 'SuppressionPersonnel',\n",
       " 'EMSUnits',\n",
       " 'EMSPersonnel',\n",
       " 'OtherUnits',\n",
       " 'OtherPersonnel',\n",
       " 'FirstUnitOnScene',\n",
       " 'EstimatedPropertyLoss',\n",
       " 'EstimatedContentsLoss',\n",
       " 'FireFatalities',\n",
       " 'FireInjuries',\n",
       " 'CivilianFatalities',\n",
       " 'CivilianInjuries',\n",
       " 'NumberofAlarms',\n",
       " 'PrimarySituation',\n",
       " 'MutualAid',\n",
       " 'ActionTakenPrimary',\n",
       " 'ActionTakenSecondary',\n",
       " 'ActionTakenOther',\n",
       " 'DetectorAlertedOccupants',\n",
       " 'PropertyUse',\n",
       " 'AreaofFireOrigin',\n",
       " 'IgnitionCause',\n",
       " 'IgnitionFactorPrimary',\n",
       " 'IgnitionFactorSecondary',\n",
       " 'HeatSource',\n",
       " 'ItemFirstIgnited',\n",
       " 'HumanFactorsAssociatedwithIgnition',\n",
       " 'StructureType',\n",
       " 'StructureStatus',\n",
       " 'FloorofFireOrigin',\n",
       " 'FireSpread',\n",
       " 'NoFlameSpead',\n",
       " 'Numberoffloorswithminimumdamage',\n",
       " 'Numberoffloorswithsignificantdamage',\n",
       " 'Numberoffloorswithheavydamage',\n",
       " 'Numberoffloorswithextremedamage',\n",
       " 'DetectorsPresent',\n",
       " 'DetectorType',\n",
       " 'DetectorOperation',\n",
       " 'DetectorEffectiveness',\n",
       " 'DetectorFailureReason',\n",
       " 'AutomaticExtinguishingSystemPresent',\n",
       " 'AutomaticExtinguishingSytemType',\n",
       " 'AutomaticExtinguishingSytemPerfomance',\n",
       " 'AutomaticExtinguishingSytemFailureReason',\n",
       " 'NumberofSprinklerHeadsOperating',\n",
       " 'SupervisorDistrict',\n",
       " 'AnalysisNeighborhood',\n",
       " 'point',\n",
       " 'NeighborhoodsOld',\n",
       " 'ZipCodes',\n",
       " 'FirePreventionDistricts',\n",
       " 'PoliceDistricts',\n",
       " 'SupervisorDistricts',\n",
       " 'CivicCenterHarmReductionProjectBoundary',\n",
       " '2017FixItZones',\n",
       " 'HSOCZones',\n",
       " 'CentralMarketTenderloinBoundary',\n",
       " 'CentralMarketTenderloinBoundaryPolygonUpdated',\n",
       " 'HSOCZonesasof20180605',\n",
       " 'Neighborhoods',\n",
       " 'SFFindNeighborhoods',\n",
       " 'CurrentPoliceDistricts',\n",
       " 'CurrentSupervisorDistricts',\n",
       " 'AnalysisNeighborhoods']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./data/output/fireincidents\"\n",
    "file_df.write.format(\"parquet\").mode(\"overwrite\").save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Structured Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, FloatType, DateType, BooleanType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True), #third param is nullable\n",
    "    StructField(\"first_name\", StringType(), True), \n",
    "    StructField(\"last_name\", StringType(), True), \n",
    "    StructField(\"fav_movies\", ArrayType(StringType()), True), \n",
    "    StructField(\"salary\", FloatType(), True), \n",
    "    StructField(\"image_url\", StringType(), True),\n",
    "    StructField(\"date_of_birth\", DateType(), True),\n",
    "    StructField(\"active\", BooleanType(), True)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = './data/persons.json'\n",
    "persons_df = spark.read.json(json_file_path, persons_schema, multiLine = \"True\") #multiLine is to specify an entry has multiple lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- fav_movies: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- salary: float (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- date_of_birth: date (nullable = true)\n",
      " |-- active: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-------------------------------------------------------------+-------+-----------------------------------------------+-------------+------+\n",
      "|id |first_name|last_name|fav_movies                                                   |salary |image_url                                      |date_of_birth|active|\n",
      "+---+----------+---------+-------------------------------------------------------------+-------+-----------------------------------------------+-------------+------+\n",
      "|1  |Drucy     |Poppy    |[I giorni contati]                                           |1463.36|http://dummyimage.com/126x166.png/cc0000/ffffff|1991-02-16   |true  |\n",
      "|2  |Emelyne   |Blaza    |[Musketeer, The, Topralli]                                   |3006.04|http://dummyimage.com/158x106.bmp/cc0000/ffffff|1991-11-02   |false |\n",
      "|3  |Max       |Rettie   |[The Forgotten Space, Make It Happen]                        |1422.88|http://dummyimage.com/237x140.jpg/ff4444/ffffff|1990-03-03   |false |\n",
      "|4  |Ilario    |Kean     |[Up Close and Personal]                                      |3561.36|http://dummyimage.com/207x121.jpg/cc0000/ffffff|1987-06-09   |true  |\n",
      "|5  |Toddy     |Drexel   |[Walk in the Clouds, A]                                      |4934.87|http://dummyimage.com/116x202.png/cc0000/ffffff|1992-10-28   |true  |\n",
      "|6  |Oswald    |Petrolli |[Wing and the Thigh, The (L'aile ou la cuisse)]              |1153.23|http://dummyimage.com/137x172.jpg/5fa2dd/ffffff|1986-09-02   |false |\n",
      "|7  |Adrian    |Clarey   |[Walking Tall, Paradise, Hawaiian Style]                     |1044.73|http://dummyimage.com/244x218.bmp/cc0000/ffffff|1971-08-24   |false |\n",
      "|8  |Dominica  |Goodnow  |[Hearts Divided]                                             |1147.76|http://dummyimage.com/112x203.jpg/dddddd/000000|1973-08-27   |false |\n",
      "|9  |Emory     |Slocomb  |[Snake and Crane Arts of Shaolin (She hao ba bu), Mala Noche]|1082.11|http://dummyimage.com/138x226.jpg/cc0000/ffffff|1974-06-08   |true  |\n",
      "|10 |Jeremias  |Bode     |[Farewell to Arms, A]                                        |3472.63|http://dummyimage.com/243x108.bmp/dddddd/000000|1997-08-02   |true  |\n",
      "+---+----------+---------+-------------------------------------------------------------+-------+-----------------------------------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns and Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|first_name|last_name|date_of_birth|\n",
      "+----------+---------+-------------+\n",
      "|     Drucy|    Poppy|   1991-02-16|\n",
      "|   Emelyne|    Blaza|   1991-11-02|\n",
      "|       Max|   Rettie|   1990-03-03|\n",
      "|    Ilario|     Kean|   1987-06-09|\n",
      "|     Toddy|   Drexel|   1992-10-28|\n",
      "+----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select(col(\"first_name\"), col(\"last_name\"), col(\"date_of_birth\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------+\n",
      "|first_name|last_name|date_of_birth|\n",
      "+----------+---------+-------------+\n",
      "|     Drucy|    Poppy|   1991-02-16|\n",
      "|   Emelyne|    Blaza|   1991-11-02|\n",
      "|       Max|   Rettie|   1990-03-03|\n",
      "|    Ilario|     Kean|   1987-06-09|\n",
      "|     Toddy|   Drexel|   1992-10-28|\n",
      "+----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select(expr(\"first_name\"), expr(\"last_name\"), expr(\"date_of_birth\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above appear to do the same thing\n",
    "from pyspark.sql.functions import concat_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------------+\n",
      "|       full_name| salary|   salary_increase|\n",
      "+----------------+-------+------------------+\n",
      "|     Drucy Poppy|1463.36|1609.6959838867188|\n",
      "|   Emelyne Blaza|3006.04|  3306.64404296875|\n",
      "|      Max Rettie|1422.88|1565.1680053710938|\n",
      "|     Ilario Kean|3561.36|3917.4961181640624|\n",
      "|    Toddy Drexel|4934.87|  5428.35712890625|\n",
      "| Oswald Petrolli|1153.23| 1268.552978515625|\n",
      "|   Adrian Clarey|1044.73| 1149.202978515625|\n",
      "|Dominica Goodnow|1147.76|1262.5360107421875|\n",
      "|   Emory Slocomb|1082.11|1190.3209838867188|\n",
      "|   Jeremias Bode|3472.63|  3819.89287109375|\n",
      "+----------------+-------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Col Example\n",
    "(persons_df.select(concat_ws(' ', col(\"first_name\"), col(\"last_name\"))\n",
    "                   .alias(\"full_name\"), \n",
    "                   col(\"salary\"),(col(\"salary\") * 0.10 + col(\"salary\"))\n",
    "                   .alias(\"salary_increase\"))).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------------+\n",
      "|       full_name| salary|   salary_increase|\n",
      "+----------------+-------+------------------+\n",
      "|     Drucy Poppy|1463.36|1609.6959838867188|\n",
      "|   Emelyne Blaza|3006.04|  3306.64404296875|\n",
      "|      Max Rettie|1422.88|1565.1680053710938|\n",
      "|     Ilario Kean|3561.36|3917.4961181640624|\n",
      "|    Toddy Drexel|4934.87|  5428.35712890625|\n",
      "| Oswald Petrolli|1153.23| 1268.552978515625|\n",
      "|   Adrian Clarey|1044.73| 1149.202978515625|\n",
      "|Dominica Goodnow|1147.76|1262.5360107421875|\n",
      "|   Emory Slocomb|1082.11|1190.3209838867188|\n",
      "|   Jeremias Bode|3472.63|  3819.89287109375|\n",
      "+----------------+-------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Expr Example - main diff is you can assign a string expression within the expression function\n",
    "# to perform explicit calculations\n",
    "(persons_df.select(concat_ws(' ', col(\"first_name\"), col(\"last_name\"))\n",
    "                   .alias(\"full_name\"), \n",
    "                   col(\"salary\"),expr(\"salary * 0.10 + salary\")\n",
    "                   .alias(\"salary_increase\"))).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter and Where Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|      Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  3|       Max|     Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|\n",
      "|  6|    Oswald|   Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|\n",
      "|  7|    Adrian|     Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|\n",
      "|  8|  Dominica|    Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|\n",
      "|  9|     Emory|    Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 11|   Timothy|     Ervine|[Land of the Lost...|1147.61|http://dummyimage...|   1971-06-02| false|\n",
      "| 12|   Leanora|     Gooder|[It's All About L...|1327.02|http://dummyimage...|   1981-12-17| false|\n",
      "| 13|  Claiborn|     Denham|[McCullin, Max Pa...|2623.33|http://dummyimage...|   1996-03-07| false|\n",
      "| 15|    Feodor|Nancekivell|   [Monsoon Wedding]|2218.46|http://dummyimage...|   2000-10-07| false|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#both expressions produce the same results\n",
    "persons_df.filter(\"salary <= 3000\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|      Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  3|       Max|     Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|\n",
      "|  6|    Oswald|   Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|\n",
      "|  7|    Adrian|     Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|\n",
      "|  8|  Dominica|    Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|\n",
      "|  9|     Emory|    Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 11|   Timothy|     Ervine|[Land of the Lost...|1147.61|http://dummyimage...|   1971-06-02| false|\n",
      "| 12|   Leanora|     Gooder|[It's All About L...|1327.02|http://dummyimage...|   1981-12-17| false|\n",
      "| 13|  Claiborn|     Denham|[McCullin, Max Pa...|2623.33|http://dummyimage...|   1996-03-07| false|\n",
      "| 15|    Feodor|Nancekivell|   [Monsoon Wedding]|2218.46|http://dummyimage...|   2000-10-07| false|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.where(\"salary <= 3000\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|\n",
      "| 16|   Margaux| Archbold|[And Now a Word f...|1013.75|http://dummyimage...|   1988-07-29|  true|\n",
      "| 26|     Clive|      Lax|             [Rabid]|2126.87|http://dummyimage...|   1981-10-26|  true|\n",
      "| 33|  Sherline|  Primett|   [Jungle Fighters]|2309.39|http://dummyimage...|   1972-07-23|  true|\n",
      "| 34|     Davis|    Pinks|          [Hounddog]|1337.14|http://dummyimage...|   1989-07-27|  true|\n",
      "| 37|    Carlen|  Sharply|[Dr. Jekyll and M...|2051.85|http://dummyimage...|   2002-06-01|  true|\n",
      "| 40|    Jordan|   Lorant|[Shockproof, Bach...|2183.91|http://dummyimage...|   1979-07-29|  true|\n",
      "| 49| Kendricks|      Kee|   [Flower & Garnet]|2304.39|http://dummyimage...|   1999-11-14|  true|\n",
      "| 57|   Krystle|  Shovell|[Doomsday, Flight...|2260.76|http://dummyimage...|   1987-09-01|  true|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.where((col(\"salary\") <= 3000) & (col(\"active\") == True)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|  last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "| 14|   Ambrosi|   Vidineev|[Wall Street: Mon...|4550.88|http://dummyimage...|   1989-07-20|  true|\n",
      "| 15|    Feodor|Nancekivell|   [Monsoon Wedding]|2218.46|http://dummyimage...|   2000-10-07| false|\n",
      "| 18|     Alfie|   Hatliffe|     [Lord of Tears]| 3893.1|http://dummyimage...|   1989-06-21|  true|\n",
      "| 25|     Kelcy|     Wogdon|    [Iron Mask, The]|4512.51|http://dummyimage...|   2000-10-20|  true|\n",
      "| 32|      Redd|   Akenhead|[Century of the D...| 2470.9|http://dummyimage...|   2000-06-05| false|\n",
      "| 34|     Davis|      Pinks|          [Hounddog]|1337.14|http://dummyimage...|   1989-07-27|  true|\n",
      "| 61|    Shanna|    Samples|[Thomas in Love (...| 2703.0|http://dummyimage...|   1989-07-07| false|\n",
      "| 69|  Annabell|    Doughty|[Entertaining Ang...|2022.57|http://dummyimage...|   2000-09-03|  true|\n",
      "| 74|     Micky|     Umfrey|[Haunted House, T...|1271.82|http://dummyimage...|   1989-07-04| false|\n",
      "| 88|     Jobie|    Maughan|[Devils on the Do...| 3899.2|http://dummyimage...|   2000-02-07| false|\n",
      "+---+----------+-----------+--------------------+-------+--------------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.filter((year(\"date_of_birth\") == 2000) | (year(\"date_of_birth\") == 1989)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "| 11|   Timothy|   Ervine|[Land of the Lost...|1147.61|http://dummyimage...|   1971-06-02| false|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.where(array_contains(persons_df.fav_movies, \"Land of the Lost\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinct, Drop Duplicates, Order By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|active|\n",
      "+------+\n",
      "|  true|\n",
      "| false|\n",
      "| false|\n",
      "|  true|\n",
      "|  true|\n",
      "| false|\n",
      "| false|\n",
      "| false|\n",
      "|  true|\n",
      "|  true|\n",
      "+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select(\"active\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|active|\n",
      "+------+\n",
      "|  true|\n",
      "| false|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons_df.select(\"active\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|first_name|year|active|\n",
      "+----------+----+------+\n",
      "|    Adrian|1971| false|\n",
      "|   Feodora|1971|  true|\n",
      "|       Sky|1971| false|\n",
      "|   Timothy|1971| false|\n",
      "|    Lucita|1972|  true|\n",
      "|      Rodi|1972| false|\n",
      "|  Sherline|1972|  true|\n",
      "|     Toddy|1972|  true|\n",
      "|  Dominica|1973| false|\n",
      "|    Kelila|1973|  true|\n",
      "+----------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(persons_df.select(col(\"first_name\"),\n",
    "                  year(col(\"date_of_birth\")).alias(\"year\"),\n",
    "                  col(\"active\"))\n",
    "                .orderBy(\"year\",\"first_name\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|first_name|year|active|\n",
      "+----------+----+------+\n",
      "|    Adrian|1971| false|\n",
      "|   Feodora|1971|  true|\n",
      "|      Rodi|1972| false|\n",
      "|  Sherline|1972|  true|\n",
      "|  Dominica|1973| false|\n",
      "|    Kelila|1973|  true|\n",
      "|   Balduin|1974| false|\n",
      "|     Emory|1974|  true|\n",
      "|    Janean|1975|  true|\n",
      "|       Bev|1976|  true|\n",
      "+----------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop duplicates\n",
    "rem_dups = (persons_df.select(col(\"first_name\"),\n",
    "                  year(col(\"date_of_birth\")).alias(\"year\"),\n",
    "                  col(\"active\"))\n",
    "                .dropDuplicates([\"year\",\"active\"])\n",
    "                .orderBy(\"year\",\"first_name\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+\n",
      "|first_name|year|active|\n",
      "+----------+----+------+\n",
      "|     Daron|2002|  true|\n",
      "|    Virgie|2002|  true|\n",
      "|    Carlen|2002|  true|\n",
      "|   Lorilee|2002| false|\n",
      "|    Maxine|2001| false|\n",
      "|    Feodor|2000| false|\n",
      "|     Kelcy|2000|  true|\n",
      "|  Annabell|2000|  true|\n",
      "|      Redd|2000| false|\n",
      "|     Jobie|2000| false|\n",
      "+----------+----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# order by year descending\n",
    "(persons_df.select(col(\"first_name\"),\n",
    "                  year(col(\"date_of_birth\")).alias(\"year\"),\n",
    "                  col(\"active\"))\n",
    "                .orderBy(\"year\", ascending=False)).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rows and Unions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_row = Row(101,\"Robert\",\"Owens\",[\"Men in Black III\",\"Home Alone\"],4300.64,\"http://someimage.com\",\"1964-08-14\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_rows_list = [\n",
    "    Row(102,\"Kenny\",\"Bob\",[\"Men in Black III\",\"Home Alone\"],4300.64,\"http://someimage.com\",\"1964-08-14\",True),\n",
    "    Row(103,\"Sara\",\"Devine\",[\"Men in Black III\",\"Home Alone\"],4300.64,\"http://someimage.com\",\"1964-08-14\",True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_rows_list.append(persons_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Row(102, 'Kenny', 'Bob', ['Men in Black III', 'Home Alone'], 4300.64, 'http://someimage.com', '1964-08-14', True)>, <Row(103, 'Sara', 'Devine', ['Men in Black III', 'Home Alone'], 4300.64, 'http://someimage.com', '1964-08-14', True)>, <Row(101, 'Robert', 'Owens', ['Men in Black III', 'Home Alone'], 4300.64, 'http://someimage.com', '1964-08-14', True)>]\n"
     ]
    }
   ],
   "source": [
    "print(person_rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_persons_df = spark.createDataFrame(person_rows_list, [\"id\",\"first_name\",\"last_name\",\"fav_movies\",\"salary\",\"img_url\",\"active_ind\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+------------------+--------------------+-------------+------+\n",
      "| id|first_name|last_name|          fav_movies|            salary|           image_url|date_of_birth|active|\n",
      "+---+----------+---------+--------------------+------------------+--------------------+-------------+------+\n",
      "|103|      Sara|   Devine|[Men in Black III...|           4300.64|http://someimage.com|   1964-08-14|  true|\n",
      "|102|     Kenny|      Bob|[Men in Black III...|           4300.64|http://someimage.com|   1964-08-14|  true|\n",
      "|101|    Robert|    Owens|[Men in Black III...|           4300.64|http://someimage.com|   1964-08-14|  true|\n",
      "|100|    Virgie| Domanski|[Horseman, The, S...| 2165.929931640625|http://dummyimage...|   2002-01-05|  true|\n",
      "| 99|   Rozalie|   Wannop|[Suddenly, The No...|1259.6400146484375|http://dummyimage...|   1997-03-25| false|\n",
      "| 98|     Davin|     Labb|[Viva Riva!, Kill...| 1452.739990234375|http://dummyimage...|   1988-01-27|  true|\n",
      "| 97|      Rodi|   Farnan|[Code, The (Menta...|   2325.8798828125|http://dummyimage...|   1972-01-04| false|\n",
      "| 96|       Dew| Coopland|              [Rush]|  2725.56005859375|http://dummyimage...|   1986-11-14| false|\n",
      "| 95|      Cobb|  MacLure|[Storage 24, His ...|1621.1700439453125|http://dummyimage...|   1994-06-28| false|\n",
      "| 94|    Bennie|   Knight|[House on Carroll...| 2370.239990234375|http://dummyimage...|   1977-08-27| false|\n",
      "+---+----------+---------+--------------------+------------------+--------------------+-------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_persons_df = persons_df.union(new_persons_df)\n",
    "add_persons_df.sort(desc(\"id\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding, Renaming and Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+------------------+\n",
      "| id|first_name|last_name|          fav_movies| salary|           image_url|date_of_birth|active|       salary_incr|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+------------------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|1609.6959838867188|\n",
      "|  2|   Emelyne|    Blaza|[Musketeer, The, ...|3006.04|http://dummyimage...|   1991-11-02| false|  3306.64404296875|\n",
      "|  3|       Max|   Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|1565.1680053710938|\n",
      "|  4|    Ilario|     Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true|3917.4961181640624|\n",
      "|  5|     Toddy|   Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|  5428.35712890625|\n",
      "|  6|    Oswald| Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false| 1268.552978515625|\n",
      "|  7|    Adrian|   Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false| 1149.202978515625|\n",
      "|  8|  Dominica|  Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|1262.5360107421875|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|1190.3209838867188|\n",
      "| 10|  Jeremias|     Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|  3819.89287109375|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aug_persons_df1 = persons_df.withColumn(\"salary_incr\", expr(\"salary * 0.10 + salary\"))\n",
    "aug_persons_df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'first_name',\n",
       " 'last_name',\n",
       " 'fav_movies',\n",
       " 'salary',\n",
       " 'image_url',\n",
       " 'date_of_birth',\n",
       " 'active',\n",
       " 'salary_incr']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_persons_df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_persons_df2 = (aug_persons_df1\n",
    "                   .withColumn(\"birth_year\", year(\"date_of_birth\"))\n",
    "                   .withColumnRenamed(\"fav_movies\", \"movies\")\n",
    "                   .withColumn(\"salary_x10\", round(col(\"salary_incr\"), 2))\n",
    "                   .drop(\"salary_incr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+----------+----------+\n",
      "| id|first_name|last_name|              movies| salary|           image_url|date_of_birth|active|birth_year|salary_x10|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+----------+----------+\n",
      "|  1|     Drucy|    Poppy|  [I giorni contati]|1463.36|http://dummyimage...|   1991-02-16|  true|      1991|    1609.7|\n",
      "|  2|   Emelyne|    Blaza|[Musketeer, The, ...|3006.04|http://dummyimage...|   1991-11-02| false|      1991|   3306.64|\n",
      "|  3|       Max|   Rettie|[The Forgotten Sp...|1422.88|http://dummyimage...|   1990-03-03| false|      1990|   1565.17|\n",
      "|  4|    Ilario|     Kean|[Up Close and Per...|3561.36|http://dummyimage...|   1987-06-09|  true|      1987|    3917.5|\n",
      "|  5|     Toddy|   Drexel|[Walk in the Clou...|4934.87|http://dummyimage...|   1992-10-28|  true|      1992|   5428.36|\n",
      "|  6|    Oswald| Petrolli|[Wing and the Thi...|1153.23|http://dummyimage...|   1986-09-02| false|      1986|   1268.55|\n",
      "|  7|    Adrian|   Clarey|[Walking Tall, Pa...|1044.73|http://dummyimage...|   1971-08-24| false|      1971|    1149.2|\n",
      "|  8|  Dominica|  Goodnow|    [Hearts Divided]|1147.76|http://dummyimage...|   1973-08-27| false|      1973|   1262.54|\n",
      "|  9|     Emory|  Slocomb|[Snake and Crane ...|1082.11|http://dummyimage...|   1974-06-08|  true|      1974|   1190.32|\n",
      "| 10|  Jeremias|     Bode|[Farewell to Arms...|3472.63|http://dummyimage...|   1997-08-02|  true|      1997|   3819.89|\n",
      "+---+----------+---------+--------------------+-------+--------------------+-------------+------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aug_persons_df2.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Missing or Bad Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_movies_list = [Row(None, None, None),\n",
    "                   Row(None, None, 2020),\n",
    "                   Row(\"John Doe\", \"Awesome Movie\", None),\n",
    "                   Row(None, \"Awesome Movie\", 2021),\n",
    "                   Row(\"Mary Jane\", None, 2019),\n",
    "                   Row(\"Vikter Duplaix\", \"Not another teen movie\", 2001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Row(None, None, None)>,\n",
       " <Row(None, None, 2020)>,\n",
       " <Row('John Doe', 'Awesome Movie', None)>,\n",
       " <Row(None, 'Awesome Movie', 2021)>,\n",
       " <Row('Mary Jane', None, 2019)>,\n",
       " <Row('Vikter Duplaix', 'Not another teen movie', 2001)>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_movies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_movies_columns = [\"actor_name\",\"movie_title\",\"produced\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_movies_df = spark.createDataFrame(bad_movies_list, schema=bad_movies_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------+\n",
      "|    actor_name|         movie_title|produced|\n",
      "+--------------+--------------------+--------+\n",
      "|          null|                null|    null|\n",
      "|          null|                null|    2020|\n",
      "|      John Doe|       Awesome Movie|    null|\n",
      "|          null|       Awesome Movie|    2021|\n",
      "|     Mary Jane|                null|    2019|\n",
      "|Vikter Duplaix|Not another teen ...|    2001|\n",
      "+--------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------+\n",
      "|    actor_name|         movie_title|produced|\n",
      "+--------------+--------------------+--------+\n",
      "|Vikter Duplaix|Not another teen ...|    2001|\n",
      "+--------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using na functinon - null any\n",
    "bad_movies_df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------+\n",
      "|    actor_name|         movie_title|produced|\n",
      "+--------------+--------------------+--------+\n",
      "|Vikter Duplaix|Not another teen ...|    2001|\n",
      "+--------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.na.drop(\"any\").show() #does the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------+\n",
      "|    actor_name|         movie_title|produced|\n",
      "+--------------+--------------------+--------+\n",
      "|          null|                null|    2020|\n",
      "|      John Doe|       Awesome Movie|    null|\n",
      "|          null|       Awesome Movie|    2021|\n",
      "|     Mary Jane|                null|    2019|\n",
      "|Vikter Duplaix|Not another teen ...|    2001|\n",
      "+--------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop only row where entire row has nulls\n",
    "bad_movies_df.na.drop(\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------+\n",
      "|    actor_name|         movie_title|produced|\n",
      "+--------------+--------------------+--------+\n",
      "|      John Doe|       Awesome Movie|    null|\n",
      "|     Mary Jane|                null|    2019|\n",
      "|Vikter Duplaix|Not another teen ...|    2001|\n",
      "+--------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using a filter to find non null records\n",
    "bad_movies_df.filter(col(\"actor_name\").isNull() != True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+\n",
      "|actor_name|  movie_title|produced|\n",
      "+----------+-------------+--------+\n",
      "|      null|         null|    null|\n",
      "|      null|         null|    2020|\n",
      "|      null|Awesome Movie|    2021|\n",
      "+----------+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.filter(col(\"actor_name\").isNull() != False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|         produced|\n",
      "+-------+-----------------+\n",
      "|  count|                4|\n",
      "|   mean|          2015.25|\n",
      "| stddev|9.535023160258536|\n",
      "|    min|             2001|\n",
      "|    max|             2021|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show statistics in regards to a column\n",
    "bad_movies_df.describe(\"produced\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|summary|    actor_name|\n",
      "+-------+--------------+\n",
      "|  count|             3|\n",
      "|   mean|          null|\n",
      "| stddev|          null|\n",
      "|    min|      John Doe|\n",
      "|    max|Vikter Duplaix|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.describe(\"actor_name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_list = [(\"Joe\", 85),\n",
    "                (\"Jane\", 90),\n",
    "                (\"Mary\", 55)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_columns = [\"name\",\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_df = spark.createDataFrame(students_list, schema=students_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name|score|\n",
      "+----+-----+\n",
      "| Joe|   85|\n",
      "|Jane|   90|\n",
      "|Mary|   55|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterGrade(score:int):\n",
    "    grade = ''\n",
    "    if score >= 90:\n",
    "        grade = 'A'\n",
    "    elif score >= 80:\n",
    "        grade = 'B'\n",
    "    else:\n",
    "        grade = 'F'\n",
    "    \n",
    "    return grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the spark function\n",
    "letterGradeUDF = udf(letterGrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|name|score|grade|\n",
      "+----+-----+-----+\n",
      "| Joe|   85|    B|\n",
      "|Jane|   90|    A|\n",
      "|Mary|   55|    F|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.select(\"name\",\"score\", letterGradeUDF(col(\"score\"))\n",
    "                   .alias(\"grade\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_file = './data/flightdata/flight-summary.csv'\n",
    "flight_summary_df = (spark.read.format(\"csv\")\n",
    "                    .option(\"header\", \"true\")\n",
    "                    .option(\"inferSchema\", \"true\")\n",
    "                           .load(flight_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4693"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_summary_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------------------------------------+------------+------------+---------+--------------------------------------------+----------------+----------+-----+\n",
      "|origin_code|origin_airport                                  |origin_city |origin_state|dest_code|dest_airport                                |dest_city       |dest_state|count|\n",
      "+-----------+------------------------------------------------+------------+------------+---------+--------------------------------------------+----------------+----------+-----+\n",
      "|BQN        |Rafael Hernández Airport                        |Aguadilla   |PR          |MCO      |Orlando International Airport               |Orlando         |FL        |441  |\n",
      "|PHL        |Philadelphia International Airport              |Philadelphia|PA          |MCO      |Orlando International Airport               |Orlando         |FL        |4869 |\n",
      "|MCI        |Kansas City International Airport               |Kansas City |MO          |IAH      |George Bush Intercontinental Airport        |Houston         |TX        |1698 |\n",
      "|SPI        |Abraham Lincoln Capital Airport                 |Springfield |IL          |ORD      |Chicago O'Hare International Airport        |Chicago         |IL        |998  |\n",
      "|SNA        |John Wayne Airport (Orange County Airport)      |Santa Ana   |CA          |PHX      |Phoenix Sky Harbor International Airport    |Phoenix         |AZ        |3846 |\n",
      "|LBB        |Lubbock Preston Smith International Airport     |Lubbock     |TX          |DEN      |Denver International Airport                |Denver          |CO        |618  |\n",
      "|ORD        |Chicago O'Hare International Airport            |Chicago     |IL          |PDX      |Portland International Airport              |Portland        |OR        |2149 |\n",
      "|EWR        |Newark Liberty International Airport            |Newark      |NJ          |STT      |Cyril E. King Airport                       |Charlotte Amalie|VI        |239  |\n",
      "|ATL        |Hartsfield-Jackson Atlanta International Airport|Atlanta     |GA          |GSP      |Greenville-Spartanburg International Airport|Greer           |SC        |2470 |\n",
      "|MCI        |Kansas City International Airport               |Kansas City |MO          |MKE      |General Mitchell International Airport      |Milwaukee       |WI        |612  |\n",
      "+-----------+------------------------------------------------+------------+------------+---------+--------------------------------------------+----------------+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_summary_df.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- origin_code: string (nullable = true)\n",
      " |-- origin_airport: string (nullable = true)\n",
      " |-- origin_city: string (nullable = true)\n",
      " |-- origin_state: string (nullable = true)\n",
      " |-- dest_code: string (nullable = true)\n",
      " |-- dest_airport: string (nullable = true)\n",
      " |-- dest_city: string (nullable = true)\n",
      " |-- dest_state: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_summary_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_summary_df = flight_summary_df.withColumnRenamed(\"count\",\"flight_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------------------------------------+------------+------------+---------+--------------------------------------------+----------------+----------+------------+\n",
      "|origin_code|origin_airport                                  |origin_city |origin_state|dest_code|dest_airport                                |dest_city       |dest_state|flight_count|\n",
      "+-----------+------------------------------------------------+------------+------------+---------+--------------------------------------------+----------------+----------+------------+\n",
      "|BQN        |Rafael Hernández Airport                        |Aguadilla   |PR          |MCO      |Orlando International Airport               |Orlando         |FL        |441         |\n",
      "|PHL        |Philadelphia International Airport              |Philadelphia|PA          |MCO      |Orlando International Airport               |Orlando         |FL        |4869        |\n",
      "|MCI        |Kansas City International Airport               |Kansas City |MO          |IAH      |George Bush Intercontinental Airport        |Houston         |TX        |1698        |\n",
      "|SPI        |Abraham Lincoln Capital Airport                 |Springfield |IL          |ORD      |Chicago O'Hare International Airport        |Chicago         |IL        |998         |\n",
      "|SNA        |John Wayne Airport (Orange County Airport)      |Santa Ana   |CA          |PHX      |Phoenix Sky Harbor International Airport    |Phoenix         |AZ        |3846        |\n",
      "|LBB        |Lubbock Preston Smith International Airport     |Lubbock     |TX          |DEN      |Denver International Airport                |Denver          |CO        |618         |\n",
      "|ORD        |Chicago O'Hare International Airport            |Chicago     |IL          |PDX      |Portland International Airport              |Portland        |OR        |2149        |\n",
      "|EWR        |Newark Liberty International Airport            |Newark      |NJ          |STT      |Cyril E. King Airport                       |Charlotte Amalie|VI        |239         |\n",
      "|ATL        |Hartsfield-Jackson Atlanta International Airport|Atlanta     |GA          |GSP      |Greenville-Spartanburg International Airport|Greer           |SC        |2470        |\n",
      "|MCI        |Kansas City International Airport               |Kansas City |MO          |MKE      |General Mitchell International Airport      |Milwaukee       |WI        |612         |\n",
      "+-----------+------------------------------------------------+------------+------------+---------+--------------------------------------------+----------------+----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_summary_df.show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### count(Col) and countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------------+\n",
      "|count(origin_airport)|count(dest_airport)|\n",
      "+---------------------+-------------------+\n",
      "|                 4693|               4693|\n",
      "+---------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count excludes counting null values\n",
    "flight_summary_df.select(count(\"origin_airport\"), count(\"dest_airport\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------+\n",
      "|    actor_name|         movie_title|produced|\n",
      "+--------------+--------------------+--------+\n",
      "|          null|                null|    null|\n",
      "|          null|                null|    2020|\n",
      "|      John Doe|       Awesome Movie|    null|\n",
      "|          null|       Awesome Movie|    2021|\n",
      "|     Mary Jane|                null|    2019|\n",
      "|Vikter Duplaix|Not another teen ...|    2001|\n",
      "+--------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_movies_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+---------------+--------+\n",
      "|count(actor_name)|count(movie_title)|count(produced)|count(1)|\n",
      "+-----------------+------------------+---------------+--------+\n",
      "|                3|                 3|              4|       6|\n",
      "+-----------------+------------------+---------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# here we see null values being ignored for the columns aside from an all count\n",
    "bad_movies_df.select(count(\"actor_name\"), count(\"movie_title\"), count(\"produced\"), count(\"*\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+----------------------------+--------+\n",
      "|count(DISTINCT origin_airport)|count(DISTINCT dest_airport)|count(1)|\n",
      "+------------------------------+----------------------------+--------+\n",
      "|                           322|                         322|    4693|\n",
      "+------------------------------+----------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_summary_df.select(countDistinct(\"origin_airport\"), countDistinct(\"dest_airport\"), count(\"*\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min, Max, Sum, SumDistinct and Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min, max, sum, sumDistinct, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|min(flight_count)|max(flight_count)|\n",
      "+-----------------+-----------------+\n",
      "|                1|            13744|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_summary_df.select(min(\"flight_count\"), max(\"flight_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|sum(flight_count)|\n",
      "+-----------------+\n",
      "|          5332914|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_summary_df.select(sum(\"flight_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name|score|\n",
      "+----+-----+\n",
      "| Joe|   85|\n",
      "|Jane|   90|\n",
      "|Mary|   55|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(score)|\n",
      "+----------+\n",
      "|       230|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.select(sum(\"score\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name|score|\n",
      "+----+-----+\n",
      "| Joe|   85|\n",
      "|Jane|   90|\n",
      "|Mary|   55|\n",
      "| Joe|   85|\n",
      "|Jane|   90|\n",
      "|Mary|   55|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df = students_df.union(students_df)\n",
    "students_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(score)|\n",
      "+----------+\n",
      "|       460|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.select(sum(\"score\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|sum(DISTINCT score)|\n",
      "+-------------------+\n",
      "|                230|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.select(sumDistinct(\"score\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|sum(DISTINCT flight_count)|\n",
      "+--------------------------+\n",
      "|                   3612257|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_summary_df.select(sumDistinct(\"flight_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------------------------------+\n",
      "| avg(flight_count)|(sum(flight_count) / count(flight_count))|\n",
      "+------------------+-----------------------------------------+\n",
      "|1136.3549968037503|                       1136.3549968037503|\n",
      "+------------------+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_summary_df.select(avg(\"flight_count\"), sum(\"flight_count\") / count(\"flight_count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation with Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+-----+\n",
      "|origin_airport                                  |count|\n",
      "+------------------------------------------------+-----+\n",
      "|Hartsfield-Jackson Atlanta International Airport|169  |\n",
      "|Chicago O'Hare International Airport            |162  |\n",
      "|Dallas/Fort Worth International Airport         |148  |\n",
      "|Denver International Airport                    |139  |\n",
      "|Minneapolis-Saint Paul International Airport    |120  |\n",
      "+------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_summary_df.groupBy(\"origin_airport\").count().orderBy(\"count\", ascending=False).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------+----------------+\n",
      "|origin_airport                                                        |max_flight_count|\n",
      "+----------------------------------------------------------------------+----------------+\n",
      "|San Francisco International Airport                                   |13744           |\n",
      "|Los Angeles International Airport                                     |13457           |\n",
      "|John F. Kennedy International Airport (New York International Airport)|12016           |\n",
      "|McCarran International Airport                                        |9715            |\n",
      "|LaGuardia Airport (Marine Air Terminal)                               |9639            |\n",
      "+----------------------------------------------------------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get airports with highest flight counts using max\n",
    "(flight_summary_df.groupBy(\"origin_airport\")\n",
    " .agg(max(\"flight_count\").alias(\"max_flight_count\"))\n",
    " .orderBy(\"max_flight_count\", ascending=False)).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-----+\n",
      "|origin_state|origin_city  |count|\n",
      "+------------+-------------+-----+\n",
      "|CA          |San Francisco|80   |\n",
      "|CA          |Los Angeles  |80   |\n",
      "|CA          |San Diego    |47   |\n",
      "|CA          |Oakland      |35   |\n",
      "|CA          |Sacramento   |27   |\n",
      "+------------+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(flight_summary_df.groupBy(\"origin_state\",\"origin_city\")\n",
    " .count()\n",
    " .where(col(\"origin_state\") == \"CA\")\n",
    " .orderBy(\"count\", ascending=False).show(5,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+-----------------+-----------------+-----------------+-------------------+\n",
      "|origin_airport                                   |max(flight_count)|min(flight_count)|sum(flight_count)|count(flight_count)|\n",
      "+-------------------------------------------------+-----------------+-----------------+-----------------+-------------------+\n",
      "|Melbourne International Airport                  |1332             |1332             |1332             |1                  |\n",
      "|San Diego International Airport (Lindbergh Field)|6942             |4                |70207            |46                 |\n",
      "|Eppley Airfield                                  |2083             |1                |16753            |21                 |\n",
      "|Kahului Airport                                  |8313             |67               |20627            |18                 |\n",
      "|Austin-Bergstrom International Airport           |4674             |8                |42067            |41                 |\n",
      "+-------------------------------------------------+-----------------+-----------------+-----------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(flight_summary_df.groupBy(\"origin_airport\")\n",
    " .agg(max(\"flight_count\"),\n",
    "      min(\"flight_count\"),\n",
    "      sum(\"flight_count\"),\n",
    "      count(\"flight_count\"))).show(5,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
